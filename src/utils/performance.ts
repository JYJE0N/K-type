// ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìœ í‹¸ë¦¬í‹°

export interface PerformanceMetrics {
  inputLatency: number
  renderTime: number
  memoryUsage: number
  timestamp: number
}

export class PerformanceMonitor {
  private static instance: PerformanceMonitor
  private metrics: PerformanceMetrics[] = []
  private lastInputTime = 0
  private renderStartTime = 0

  static getInstance(): PerformanceMonitor {
    if (!this.instance) {
      this.instance = new PerformanceMonitor()
    }
    return this.instance
  }

  // ì…ë ¥ ì§€ì—°ì‹œê°„ ì¸¡ì • ì‹œì‘
  startInputMeasurement(): void {
    this.lastInputTime = performance.now()
  }

  // ì…ë ¥ ì§€ì—°ì‹œê°„ ì¸¡ì • ì™„ë£Œ
  endInputMeasurement(): number {
    const now = performance.now()
    const latency = now - this.lastInputTime
    return latency
  }

  // ë Œë”ë§ ì‹œê°„ ì¸¡ì • ì‹œì‘
  startRenderMeasurement(): void {
    this.renderStartTime = performance.now()
  }

  // ë Œë”ë§ ì‹œê°„ ì¸¡ì • ì™„ë£Œ
  endRenderMeasurement(): number {
    const now = performance.now()
    const renderTime = now - this.renderStartTime
    return renderTime
  }

  // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
  measureMemoryUsage(): number {
    if ('memory' in performance) {
      const memory = (performance as Performance & { memory?: { usedJSHeapSize: number } }).memory
      return memory ? memory.usedJSHeapSize / 1024 / 1024 : 0 // MB ë‹¨ìœ„
    }
    return 0
  }

  // ì „ì²´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  collectMetrics(): PerformanceMetrics {
    const inputLatency = this.endInputMeasurement()
    const renderTime = this.endRenderMeasurement()
    const memoryUsage = this.measureMemoryUsage()
    const timestamp = Date.now()

    const metrics: PerformanceMetrics = {
      inputLatency,
      renderTime,
      memoryUsage,
      timestamp
    }

    this.metrics.push(metrics)
    
    // ìµœê·¼ 100ê°œ ë©”íŠ¸ë¦­ë§Œ ìœ ì§€
    if (this.metrics.length > 100) {
      this.metrics.shift()
    }

    return metrics
  }

  // í‰ê·  ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
  getAverageMetrics(): PerformanceMetrics | null {
    if (this.metrics.length === 0) return null

    const totals = this.metrics.reduce(
      (acc, metric) => ({
        inputLatency: acc.inputLatency + metric.inputLatency,
        renderTime: acc.renderTime + metric.renderTime,
        memoryUsage: acc.memoryUsage + metric.memoryUsage,
        timestamp: acc.timestamp + metric.timestamp
      }),
      { inputLatency: 0, renderTime: 0, memoryUsage: 0, timestamp: 0 }
    )

    return {
      inputLatency: totals.inputLatency / this.metrics.length,
      renderTime: totals.renderTime / this.metrics.length,
      memoryUsage: totals.memoryUsage / this.metrics.length,
      timestamp: totals.timestamp / this.metrics.length
    }
  }

  // ì„±ëŠ¥ ê²½ê³  í™•ì¸
  checkPerformanceWarnings(): string[] {
    const warnings: string[] = []
    const recent = this.metrics.slice(-10) // ìµœê·¼ 10ê°œ ì¸¡ì •ê°’

    if (recent.length < 5) return warnings

    const avgInputLatency = recent.reduce((sum, m) => sum + m.inputLatency, 0) / recent.length
    const avgRenderTime = recent.reduce((sum, m) => sum + m.renderTime, 0) / recent.length
    const avgMemoryUsage = recent.reduce((sum, m) => sum + m.memoryUsage, 0) / recent.length

    // ì…ë ¥ ì§€ì—°ì‹œê°„ ê²½ê³  (ë°ìŠ¤í¬í†±: 50ms, ëª¨ë°”ì¼: 100ms)
    const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)
    const inputLatencyThreshold = isMobile ? 100 : 50

    if (avgInputLatency > inputLatencyThreshold) {
      warnings.push(`ì…ë ¥ ì§€ì—°ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤: ${avgInputLatency.toFixed(1)}ms`)
    }

    // ë Œë”ë§ ì‹œê°„ ê²½ê³  (16.67ms = 60fps)
    if (avgRenderTime > 16.67) {
      warnings.push(`ë Œë”ë§ ì‹œê°„ì´ ê¸¸ì–´ ëŠê¹€ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ${avgRenderTime.toFixed(1)}ms`)
    }

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²½ê³  (100MB)
    if (avgMemoryUsage > 100) {
      warnings.push(`ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤: ${avgMemoryUsage.toFixed(1)}MB`)
    }

    return warnings
  }

  // ë©”íŠ¸ë¦­ ë¦¬ì…‹
  reset(): void {
    this.metrics = []
    this.lastInputTime = 0
    this.renderStartTime = 0
  }

  // ë””ë²„ê·¸ìš© ë©”íŠ¸ë¦­ ì¶œë ¥
  logMetrics(): void {
    if (process.env.NODE_ENV === 'development') {
      const avg = this.getAverageMetrics()
      const warnings = this.checkPerformanceWarnings()
      
      console.group('ğŸ”§ Performance Metrics')
      console.log('ğŸ“Š Average Metrics:', avg)
      console.log('âš ï¸ Warnings:', warnings)
      console.log('ğŸ“ˆ Recent Metrics:', this.metrics.slice(-5))
      console.groupEnd()
    }
  }
}

// ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹°
export class PerformanceOptimizer {
  // ë””ë°”ìš´ìŠ¤ í•¨ìˆ˜
  static debounce<T extends (...args: unknown[]) => unknown>(
    func: T,
    delay: number
  ): (...args: Parameters<T>) => void {
    let timeoutId: NodeJS.Timeout
    return (...args: Parameters<T>) => {
      clearTimeout(timeoutId)
      timeoutId = setTimeout(() => func(...args), delay)
    }
  }

  // ìŠ¤ë¡œí‹€ í•¨ìˆ˜
  static throttle<T extends (...args: unknown[]) => unknown>(
    func: T,
    delay: number
  ): (...args: Parameters<T>) => void {
    let lastCall = 0
    return (...args: Parameters<T>) => {
      const now = Date.now()
      if (now - lastCall >= delay) {
        lastCall = now
        func(...args)
      }
    }
  }

  // requestAnimationFrameì„ ì´ìš©í•œ ìµœì í™”
  static scheduleUpdate(callback: () => void): void {
    requestAnimationFrame(callback)
  }

  // ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
  static batchUpdates<T>(
    items: T[],
    batchSize: number,
    processor: (batch: T[]) => void,
    onComplete?: () => void
  ): void {
    let index = 0

    const processBatch = () => {
      const batch = items.slice(index, index + batchSize)
      if (batch.length > 0) {
        processor(batch)
        index += batchSize
        
        // ë‹¤ìŒ ë°°ì¹˜ë¥¼ ë‹¤ìŒ í”„ë ˆì„ì— ì²˜ë¦¬
        requestAnimationFrame(processBatch)
      } else if (onComplete) {
        onComplete()
      }
    }

    processBatch()
  }
}

// ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
export const performanceMonitor = PerformanceMonitor.getInstance()